#!/usr/bin/env bash
#############################################################################
# DupeFinder Pro - Advanced Duplicate File Manager for Linux
# Version: 0.0.1
# Author: Seth Morrow
# License: MIT
#
# Description:
#   Professional duplicate file finder with advanced management, reporting,
#   caching, smart deletion strategies, and critical system file protection.
#   This version includes comprehensive safety features to prevent accidental
#   deletion of system-critical files and libraries.
#
#############################################################################

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL COLORS AND FORMATTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color
BOLD='\033[1m'
DIM='\033[2m'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEFAULT CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERSION="0.0.1"
AUTHOR="Seth Morrow"
SEARCH_PATH="$(pwd)"
EXCLUDE_PATHS=("/proc" "/sys" "/dev" "/run" "/tmp" "/var/run" "/var/lock" "/mnt" "/media")
MIN_SIZE=1
MAX_SIZE=""
OUTPUT_DIR="$HOME/duplicate_reports"
HTML_REPORT="duplicates_$(date +%Y%m%d_%H%M%S).html"
CSV_REPORT=""
JSON_REPORT=""
DELETE_MODE=0
DRY_RUN=0
VERBOSE=0
QUIET=0
FOLLOW_SYMLINKS=0
EMPTY_FILES=0
HIDDEN_FILES=0
MAX_DEPTH=""
FILE_PATTERN=()
HASH_ALGORITHM="md5sum"
INTERACTIVE_DELETE=0
KEEP_NEWEST=0
KEEP_OLDEST=0
KEEP_PATH_PRIORITY=""
PROGRESS_BAR=1
TEMP_DIR=""
BACKUP_DIR=""
USE_TRASH=0
HARDLINK_MODE=0#!/usr/bin/env bash
#############################################################################
# DupeFinder Pro - Advanced Duplicate File Manager for Linux
# Version: 0.0.3
# Author: Seth Morrow
# License: MIT
#
# Description:
#Â  Â Professional duplicate file finder with advanced management, reporting,
#Â  Â caching, smart deletion strategies, and critical system file protection.
#Â  Â This version includes comprehensive safety features to prevent accidental
#Â  Â deletion of system-critical files and libraries, enhanced verbose output,
#Â  Â and significantly improved interactive mode.
#
# Fixes in this version:
# - Corrected a critical bug in the 'show_duplicate_details' function
# Â  where the pipeline for sorting files in 'keep-oldest' mode was
# Â  incomplete, causing a syntax error.
# - Updated the interactive menu prompt 'Auto Rest' to the more intuitive
# Â  'Apply to All' to improve user experience.
#
#############################################################################

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL COLORS AND FORMATTING
# Define a set of color codes to make the terminal output more readable and
# visually distinct, improving the user experience and drawing attention to
# important information like warnings and errors.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color - Resets formatting to default
BOLD='\033[1m'
DIM='\033[2m'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEFAULT CONFIGURATION
# These variables define the default behavior of the script. They can be
# overridden by command-line arguments or a configuration file.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERSION="0.0.3"
AUTHOR="Seth Morrow"
SEARCH_PATH="$(pwd)"
EXCLUDE_PATHS=("/proc" "/sys" "/dev" "/run" "/tmp" "/var/run" "/var/lock" "/mnt" "/media")
MIN_SIZE=1 # Default minimum file size in bytes (1 byte)
MAX_SIZE="" # No maximum size by default
OUTPUT_DIR="$HOME/duplicate_reports"
HTML_REPORT="duplicates_$(date +%Y%m%d_%H%M%S).html"
CSV_REPORT=""
JSON_REPORT=""
DELETE_MODE=0
DRY_RUN=0
VERBOSE=0
QUIET=0
FOLLOW_SYMLINKS=0
EMPTY_FILES=0
HIDDEN_FILES=0
MAX_DEPTH=""
FILE_PATTERN=()
HASH_ALGORITHM="md5sum" # Default hashing algorithm
INTERACTIVE_DELETE=0
KEEP_NEWEST=0
KEEP_OLDEST=0
KEEP_PATH_PRIORITY=""
PROGRESS_BAR=1
TEMP_DIR=""
BACKUP_DIR=""
USE_TRASH=0
HARDLINK_MODE=0
QUARANTINE_DIR=""
DB_CACHE="$HOME/.dupefinder_cache.db"
USE_CACHE=0
THREADS=$(nproc) # Use all available CPU cores by default
EMAIL_REPORT=""
CONFIG_FILE=""
FUZZY_MATCH=0
SIMILARITY_THRESHOLD=95
AUTO_SELECT_LOCATION=""
SAVE_CHECKSUMS=0
CHECKSUM_DB="$HOME/.dupefinder_checksums.db"
EXCLUDE_LIST_FILE=""
FAST_MODE=0
SMART_DELETE=0
LOG_FILE=""
VERIFY_MODE=0
USE_PARALLEL=0
RESUME_STATE=""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CRITICAL SYSTEM PROTECTION CONFIGURATION
# These arrays define files and paths that are critical for system operation.
# They are automatically protected from deletion unless the user explicitly
# provides the '--force-system' flag.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CRITICAL_EXTENSIONS=(
Â  ".so"Â  Â  Â # Shared libraries
Â  ".dll"Â  Â  # Windows DLLs (Wine)
Â  ".dylib"Â  # macOS dynamic libraries
Â  ".ko"Â  Â  Â # Kernel modules
Â  ".sys"Â  Â  # System files
Â  ".elf"Â  Â  # ELF executables
Â  ".a"Â  Â  Â  # Static libraries
Â  ".lib"Â  Â  # Library files
Â  ".pdb"Â  Â  # Program database
Â  ".exe"Â  Â  # Executables
)

CRITICAL_PATHS=(
Â  "/boot"Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Boot loader files
Â  "/lib"Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Essential shared libraries
Â  "/lib64"Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # 64-bit libraries
Â  "/usr/lib"Â  Â  Â  Â  Â  Â  Â  Â  Â # System libraries
Â  "/usr/lib64"Â  Â  Â  Â  Â  Â  Â  Â # 64-bit system libraries
Â  "/usr/bin"Â  Â  Â  Â  Â  Â  Â  Â  Â # User binaries
Â  "/bin"Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Essential binaries
Â  "/sbin"Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # System binaries
Â  "/usr/sbin"Â  Â  Â  Â  Â  Â  Â  Â  # Non-essential system binaries
Â  "/etc"Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # System configuration
Â  "/usr/share/dbus-1"Â  Â  Â  Â  # D-Bus configuration
Â  "/usr/share/applications"Â  # Desktop entries
)

SYSTEM_FOLDERS=(
Â  "/boot"Â  Â  Â # Boot loader and kernel
Â  "/bin"Â  Â  Â  # Essential command binaries
Â  "/sbin"Â  Â  Â # Essential system binaries
Â  "/lib"Â  Â  Â  # Essential shared libraries
Â  "/lib32"Â  Â  # 32-bit libraries
Â  "/lib64"Â  Â  # 64-bit libraries
Â  "/libx32"Â  Â # x32 ABI libraries
Â  "/usr"Â  Â  Â  # Secondary hierarchy
Â  "/etc"Â  Â  Â  # System configuration
Â  "/root"Â  Â  Â # Root user home
Â  "/snap"Â  Â  Â # Snap packages
Â  "/sys"Â  Â  Â  # Sysfs virtual filesystem
Â  "/proc"Â  Â  Â # Procfs virtual filesystem
Â  "/dev"Â  Â  Â  # Device files
Â  "/run"Â  Â  Â  # Runtime data
Â  "/srv"Â  Â  Â  # Service data
)

NEVER_DELETE_PATTERNS=(
Â  "vmlinuz*"Â  Â  Â # Linux kernel
Â  "initrd*"Â  Â  Â  # Initial ramdisk
Â  "initramfs*"Â  Â # Initial RAM filesystem
Â  "grub*"Â  Â  Â  Â  # Boot loader
Â  "ld-linux*"Â  Â  # Dynamic linker
Â  "libc.so*"Â  Â  Â # C library
Â  "libpthread*"Â  # Threading library
Â  "libdl*"Â  Â  Â  Â # Dynamic linking library
Â  "libm.so*"Â  Â  Â # Math library
Â  "busybox*"Â  Â  Â # Emergency shell
Â  "systemd*"Â  Â  Â # Init system
)

# Safety flags
SKIP_SYSTEM_FOLDERS=0Â  Â  # When enabled, excludes all system folders
FORCE_SYSTEM_DELETE=0Â  Â  # Dangerous flag, requires explicit confirmation

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STATISTICS COUNTERS
# Global variables to track statistics throughout the script's execution,
# used for the final summary and reports.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOTAL_FILES=0
TOTAL_DUPLICATES=0
TOTAL_DUPLICATE_GROUPS=0
TOTAL_SPACE_WASTED=0
FILES_DELETED=0
SPACE_FREED=0
SCAN_START_TIME=""
SCAN_END_TIME=""
DUPLICATE_GROUPS=""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SMART LOCATION PRIORITIES
# This associative array assigns a priority score to different directory
# locations. A lower number indicates a higher priority for keeping files.
# This is used by the '--smart-delete' feature.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
declare -A LOCATION_PRIORITY=(
Â  ["/home"]=1Â  Â  Â  Â  Â # User files - highest priority
Â  ["/usr/local"]=2Â  Â  # Local installations
Â  ["/opt"]=3Â  Â  Â  Â  Â  # Optional software
Â  ["/var"]=4Â  Â  Â  Â  Â  # Variable data
Â  ["/tmp"]=99Â  Â  Â  Â  Â # Temporary files - lowest priority
Â  ["/downloads"]=90Â  Â # Downloads folder
Â  ["/cache"]=95Â  Â  Â  Â # Cache directories
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLEANUP AND SIGNAL HANDLING
# Ensures proper cleanup of temporary files and state management in case
# of successful completion or an unexpected interruption (e.g., Ctrl+C).
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cleanup() {
Â  # Remove the temporary directory created for this session
Â  if [[ -n "$TEMP_DIR" && -d "$TEMP_DIR" ]]; then
Â  Â  rm -rf "$TEMP_DIR"
Â  fi
Â  # Log the session end time if logging is enabled
Â  [[ -n "$LOG_FILE" ]] && echo "$(date): Session ended" >> "$LOG_FILE"
Â  # Remove the resume state file if the scan completed successfully
Â  if [[ -n "$SCAN_END_TIME" && "$SCAN_END_TIME" -gt 0 ]]; then
Â  Â  rm -f "$HOME/.dupefinder_state"
Â  fi
}

handle_interrupt() {
Â  echo -e "\n${YELLOW}Interrupted!${NC}"
Â  if [[ $TOTAL_FILES -gt 0 ]]; then
Â  Â  echo "Processed files before interruption."
Â  Â  echo -n "Save state for resume? (y/n): "
Â  Â  read -r response
Â  Â  if [[ "$response" == "y" ]]; then
Â  Â  Â  save_state
Â  Â  Â  echo -e "${GREEN}State saved. Run script again to resume.${NC}"
Â  Â  fi
Â  fi
Â  cleanup
Â  # Exit with code 130 to indicate user interruption
Â  exit 130
}

# Set up signal handlers for graceful shutdown
trap handle_interrupt INT TERM
trap cleanup EXIT

# Create a temporary directory for session files
TEMP_DIR="/tmp/dupefinder_$$"
mkdir -p "$TEMP_DIR"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USER INTERFACE FUNCTIONS
# Functions for displaying the script's header, help information, and other
# user-facing messages.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
show_header() {
Â  clear
Â  echo -e "${CYAN}"
Â  cat << "EOF"
Â  Â  ____Â  Â  Â  Â  Â  Â  Â  Â  Â  Â _____ _Â  Â  Â  Â  Â  Â _Â  Â  Â  Â  Â  Â ____Â  Â  Â  Â  Â  Â Â 
Â  Â  |Â  _ \ _Â  Â _ _ __Â  Â ___|Â  ___(_)_ __Â  Â __| | ___ _ __|Â  _ \ _ __ ___Â Â 
Â  Â  | | | | | | | '_ \ / _ \ |_Â  | | '_ \ / _` |/ _ \ '__| |_) | '__/ _ \Â 
Â  Â  | |_| | |_| | |_) |Â  __/Â  _| | | | | | (_| |Â  __/ |Â  |Â  __/| | | (_) |
Â  Â  |____/ \__,_| .__/ \___|_|Â  Â |_|_| |_|\__,_|\___|_|Â  |_|Â  Â |_|Â  \___/Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â |_|Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
EOF
Â  echo -e "${NC}"
Â  echo -e "${WHITE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  echo -e "${BOLD}Â  Â  Â  Â  Advanced Duplicate File Manager v${VERSION}${NC}"
Â  echo -e "${DIM}Â  Â  Â  Â  Â  Â  Â  Â  by ${AUTHOR}${NC}"
Â  echo -e "${WHITE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  echo ""
}

show_help() {
Â  show_header
Â  cat << EOF
${BOLD}USAGE:${NC}
Â  Â  $0 [OPTIONS]

${BOLD}BASIC OPTIONS:${NC}
Â  Â  ${GREEN}-p, --path PATH${NC}Â  Â  Â  Â  Â  Search path (default: current directory)
Â  Â  ${GREEN}-o, --output DIR${NC}Â  Â  Â  Â  Â Output directory for reports
Â  Â  ${GREEN}-e, --exclude PATH${NC}Â  Â  Â  Â Exclude path (can be used multiple times)
Â  Â  ${GREEN}-m, --min-size SIZE${NC}Â  Â  Â  Min size (e.g., 100, 10K, 5M, 1G)
Â  Â  ${GREEN}-M, --max-size SIZE${NC}Â  Â  Â  Max size (e.g., 100, 10K, 5M, 1G)
Â  Â  ${GREEN}-h, --help${NC}Â  Â  Â  Â  Â  Â  Â  Â Show this help
Â  Â  ${GREEN}-V, --version${NC}Â  Â  Â  Â  Â  Â  Show version

${BOLD}SAFETY OPTIONS:${NC}
Â  Â  ${GREEN}--skip-system${NC}Â  Â  Â  Â  Â  Â  Skip all system folders (/usr, /lib, /bin, etc.)
Â  Â  ${GREEN}--force-system${NC}Â  Â  Â  Â  Â  Â Allow deletion of system files (DANGEROUS!)

${BOLD}SEARCH:${NC}
Â  Â  ${GREEN}-f, --follow-symlinks${NC}Â  Â  Follow symbolic links
Â  Â  ${GREEN}-z, --empty${NC}Â  Â  Â  Â  Â  Â  Â  Include empty files
Â  Â  ${GREEN}-a, --all${NC}Â  Â  Â  Â  Â  Â  Â  Â  Include hidden files
Â  Â  ${GREEN}-l, --level DEPTH${NC}Â  Â  Â  Â  Max directory depth
Â  Â  ${GREEN}-t, --pattern GLOB${NC}Â  Â  Â  Â File pattern (e.g., "*.jpg")
Â  Â  ${GREEN}--fast${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Fast mode (size+name hash)
Â  Â  ${GREEN}--fuzzy${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â  Fuzzy match by size similarity
Â  Â  ${GREEN}--similarity PCT${NC}Â  Â  Â  Â  Â Fuzzy threshold (1-100, default 95)
Â  Â  ${GREEN}--verify${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â Byte-by-byte verification before deletion

${BOLD}DELETION:${NC}
Â  Â  ${GREEN}-d, --delete${NC}Â  Â  Â  Â  Â  Â  Â Delete duplicates
Â  Â  ${GREEN}-i, --interactive${NC}Â  Â  Â  Â  Enhanced interactive mode with file preview
Â  Â  ${GREEN}-n, --dry-run${NC}Â  Â  Â  Â  Â  Â  Show actions without executing
Â  Â  ${GREEN}--trash${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â  Use trash (trash-cli) if available
Â  Â  ${GREEN}--hardlink${NC}Â  Â  Â  Â  Â  Â  Â  Â Replace duplicates with hardlinks
Â  Â  ${GREEN}--quarantine DIR${NC}Â  Â  Â  Â  Â Move duplicates to quarantine directory

${BOLD}KEEP STRATEGIES:${NC}
Â  Â  ${GREEN}-k, --keep-newest${NC}Â  Â  Â  Â  Keep newest file from each group
Â  Â  ${GREEN}-K, --keep-oldest${NC}Â  Â  Â  Â  Keep oldest file from each group
Â  Â  ${GREEN}--keep-path PATH${NC}Â  Â  Â  Â  Â Prefer files in PATH
Â  Â  ${GREEN}--smart-delete${NC}Â  Â  Â  Â  Â  Â Use location-based priorities
Â  Â  ${GREEN}--auto-select LOC${NC}Â  Â  Â  Â  Auto-select by location priority

${BOLD}PERFORMANCE:${NC}
Â  Â  ${GREEN}--threads N${NC}Â  Â  Â  Â  Â  Â  Â  Number of threads for hashing
Â  Â  ${GREEN}--cache${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â  Use SQLite cache database
Â  Â  ${GREEN}--save-checksums${NC}Â  Â  Â  Â  Â Save checksums to database
Â  Â  ${GREEN}--no-progress${NC}Â  Â  Â  Â  Â  Â  Disable progress bar
Â  Â  ${GREEN}--parallel${NC}Â  Â  Â  Â  Â  Â  Â  Â Use GNU parallel if available

${BOLD}REPORTING:${NC}
Â  Â  ${GREEN}-c, --csv FILE${NC}Â  Â  Â  Â  Â  Â Generate CSV report
Â  Â  ${GREEN}--json FILE${NC}Â  Â  Â  Â  Â  Â  Â  Generate JSON report
Â  Â  ${GREEN}--email ADDRESS${NC}Â  Â  Â  Â  Â  Email summary to ADDRESS
Â  Â  ${GREEN}--log FILE${NC}Â  Â  Â  Â  Â  Â  Â  Â Log operations to FILE
Â  Â  ${GREEN}-v, --verbose${NC}Â  Â  Â  Â  Â  Â  Enable verbose output
Â  Â  ${GREEN}-q, --quiet${NC}Â  Â  Â  Â  Â  Â  Â  Quiet mode (minimal output)

${BOLD}ADVANCED:${NC}
Â  Â  ${GREEN}-s, --sha256${NC}Â  Â  Â  Â  Â  Â  Â Use SHA256 hashing
Â  Â  ${GREEN}--sha512${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â Use SHA512 hashing
Â  Â  ${GREEN}--backup DIR${NC}Â  Â  Â  Â  Â  Â  Â Backup files before deletion
Â  Â  ${GREEN}--config FILE${NC}Â  Â  Â  Â  Â  Â  Load configuration from FILE
Â  Â  ${GREEN}--exclude-list FILE${NC}Â  Â  Â  File with paths to exclude
Â  Â  ${GREEN}--db-path FILE${NC}Â  Â  Â  Â  Â  Â Custom database path
Â  Â  ${GREEN}--resume${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â Resume previous interrupted scan

${BOLD}INTERACTIVE MODE FEATURES:${NC}
Â  Â  ${GREEN}- Enhanced file comparison with detailed metadata${NC}
Â  Â  ${GREEN}- File preview and viewer integration${NC}
Â  Â  ${GREEN}- Option to swap which file to keep${NC}
Â  Â  ${GREEN}- Auto-apply choices to remaining duplicates${NC}
Â  Â  ${GREEN}- Progress tracking through duplicate groups${NC}

${BOLD}EXAMPLES:${NC}
Â  Â  # Safe system-wide scan
Â  Â  $0 --path / --skip-system --delete --dry-run
Â  Â Â 
Â  Â  # Interactive cleanup with enhanced UI
Â  Â  $0 --path ~/Downloads --min-size 1M --interactive --verbose
Â  Â Â 
Â  Â  # Find duplicate photos and auto-select based on path priority
Â  Â  $0 --path ~/Pictures --pattern "*.jpg" --pattern "*.png" --smart-delete -v

EOF
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UTILITY FUNCTIONS
# Helper functions for size parsing, SQL escaping, and data formatting.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
parse_size() {
Â  local s="$1"
Â  if [[ "$s" =~ ^([0-9]+)([KMG]?)B?$ ]]; then
Â  Â  local n="${BASH_REMATCH[1]}"
Â  Â  local u="${BASH_REMATCH[2]}"
Â  Â  case "$u" in
Â  Â  Â  K) echo $((n*1024));;
Â  Â  Â  M) echo $((n*1024*1024));;
Â  Â  Â  G) echo $((n*1024*1024*1024));;
Â  Â  Â  *) echo "$n";;
Â  Â  esac
Â  else
Â  Â  echo "$s"
Â  fi
}

format_size() {
Â  local size=${1:-0}
Â  if command -v bc >/dev/null 2>&1; then
Â  Â  local units=(B KB MB GB TB)
Â  Â  local u=0
Â  Â  local val=$size
Â  Â  while [[ $(echo "$val >= 1024" | bc 2>/dev/null || echo 0) -eq 1 && $u -lt 4 ]]; do
Â  Â  Â  val=$(echo "scale=2; $val/1024" | bc 2>/dev/null || echo 0)
Â  Â  Â  ((u++))
Â  Â  done
Â  Â  printf "%.2f %s" "$val" "${units[$u]}"
Â  else
Â  Â  local units=(B KB MB GB TB)
Â  Â  local u=0
Â  Â  while [[ $size -ge 1024 && $u -lt 4 ]]; do
Â  Â  Â  size=$((size/1024))
Â  Â  Â  ((u++))
Â  Â  done
Â  Â  echo "$size ${units[$u]}"
Â  fi
}

sql_escape() {
Â  echo "$1" | sed "s/'/''/g; s/\\/\\\\/g"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CRITICAL SAFETY VERIFICATION FUNCTIONS
# Multiple layers of checks to prevent accidental deletion of important files,
# including system files, actively used files, and files with specific patterns.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
is_critical_system_file() {
Â  local file="$1"
Â  local basename_file
Â  basename_file=$(basename "$file")
Â  # Layer 1: Check against critical file extensions
Â  for ext in "${CRITICAL_EXTENSIONS[@]}"; do
Â  Â  [[ "$file" == *"$ext" ]] && return 0
Â  done
Â  # Layer 2: Check if file is in a critical system path
Â  for path in "${CRITICAL_PATHS[@]}"; do
Â  Â  [[ "$file" == "$path"/* ]] && return 0
Â  done
Â  # Layer 3: Check against never-delete filename patterns
Â  for pattern in "${NEVER_DELETE_PATTERNS[@]}"; do
Â  Â  if [[ "$basename_file" == $pattern ]]; then
Â  Â  Â  return 0
Â  Â  fi
Â  done
Â  # Layer 4: Check if it's a system binary in a critical location
Â  if [[ -x "$file" ]]; then
Â  Â  case "$(dirname "$file")" in
Â  Â  Â  /bin|/sbin|/usr/bin|/usr/sbin|/usr/local/bin|/usr/local/sbin)
Â  Â  Â  Â  return 0
Â  Â  Â  Â  ;;
Â  Â  esac
Â  fi
Â  return 1
}

verify_safe_to_delete() {
Â  local file="$1"
Â  # First check: Is this a critical system file?
Â  if is_critical_system_file "$file"; then
Â  Â  if [[ $FORCE_SYSTEM_DELETE -eq 1 ]]; then
Â  Â  Â  echo -e "${RED}âš  WARNING: Critical system file detected: $file${NC}"
Â  Â  Â  echo -ne "${RED}Are you ABSOLUTELY SURE you want to delete this? Type 'YES DELETE': ${NC}"
Â  Â  Â  read -r confirmation
Â  Â  Â  [[ "$confirmation" != "YES DELETE" ]] && return 1
Â  Â  else
Â  Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${RED}Â  âœ— Skipping critical system file: $file${NC}"
Â  Â  Â  return 1
Â  Â  fi
Â  fi
Â  # Second check: Is the file currently in use?
Â  if command -v lsof &>/dev/null; then
Â  Â  if lsof "$file" >/dev/null 2>&1; then
Â  Â  Â  echo -e "${YELLOW}Â  âš  File is currently in use: $file${NC}"
Â  Â  Â  if [[ $INTERACTIVE_DELETE -eq 1 ]]; then
Â  Â  Â  Â  echo -ne "${YELLOW}Â  Force delete anyway? (y/N): ${NC}"
Â  Â  Â  Â  read -r response
Â  Â  Â  Â  [[ "$response" != "y" && "$response" != "Y" ]] && return 1
Â  Â  Â  else
Â  Â  Â  Â  return 1
Â  Â  Â  fi
Â  Â  fi
Â  fi
Â  # Third check: Is this a loaded shared library?
Â  if [[ "$file" == *.so* ]]; then
Â  Â  if grep -q "$(basename "$file")" /proc/*/maps 2>/dev/null; then
Â  Â  Â  echo -e "${RED}Â  âœ— Shared library is currently loaded: $file${NC}"
Â  Â  Â  return 1
Â  Â  fi
Â  fi
Â  # Fourth check: Warn if file is owned by root
Â  local owner
Â  owner=$(stat -c '%U' "$file" 2>/dev/null)
Â  if [[ "$owner" == "root" && "$USER" != "root" ]]; then
Â  Â  echo -e "${YELLOW}Â  âš  File is owned by root: $file${NC}"
Â  fi
Â  return 0
}

is_in_system_folder() {
Â  local file="$1"
Â  for sys_folder in "${SYSTEM_FOLDERS[@]}"; do
Â  Â  [[ "$file" == "$sys_folder"/* ]] && return 0
Â  done
Â  return 1
}

show_safety_summary() {
Â  if [[ $DELETE_MODE -eq 1 || $HARDLINK_MODE -eq 1 ]]; then
Â  Â  echo -e "${YELLOW}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  Â  echo -e "${BOLD}Â  Â  Â  Â  Â  Â  Â  Â  Â SAFETY CHECK SUMMARY${NC}"
Â  Â  echo -e "${YELLOW}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  Â  echo -e "${CYAN}System Folder Protection:${NC} $([ $SKIP_SYSTEM_FOLDERS -eq 1 ] && echo "ENABLED" || echo "DISABLED")"
Â  Â  echo -e "${CYAN}Force System Delete:${NC}Â  Â  Â $([ $FORCE_SYSTEM_DELETE -eq 1 ] && echo -e "${RED}ENABLED${NC}" || echo "DISABLED")"
Â  Â  echo -e "${CYAN}Running as:${NC}Â  Â  Â  Â  Â  Â  Â  $USER"
Â  Â  echo -e "${CYAN}Delete Mode:${NC}Â  Â  Â  Â  Â  Â  Â $([ $DELETE_MODE -eq 1 ] && echo "ENABLED" || echo "DISABLED")"
Â  Â  echo -e "${CYAN}Interactive Mode:${NC}Â  Â  Â  Â  $([ $INTERACTIVE_DELETE -eq 1 ] && echo "ENABLED" || echo "DISABLED")"
Â  Â  echo -e "${CYAN}Dry Run:${NC}Â  Â  Â  Â  Â  Â  Â  Â  Â $([ $DRY_RUN -eq 1 ] && echo "YES" || echo "NO")"
Â  Â  if [[ -f "$TEMP_DIR/hashes.txt" ]]; then
Â  Â  Â  local system_files=0
Â  Â  Â  while IFS='|' read -r hash size file; do
Â  Â  Â  Â  is_in_system_folder "$file" && ((system_files++))
Â  Â  Â  done < "$TEMP_DIR/hashes.txt"
Â  Â  Â  if [[ $system_files -gt 0 ]]; then
Â  Â  Â  Â  echo -e "${YELLOW}âš  Found $system_files files in system folders${NC}"
Â  Â  Â  Â  if [[ $SKIP_SYSTEM_FOLDERS -eq 0 ]]; then
Â  Â  Â  Â  Â  echo -e "${RED}Â  These will be processed! Use --skip-system to exclude them${NC}"
Â  Â  Â  Â  fi
Â  Â  Â  fi
Â  Â  fi
Â  Â  echo -e "${YELLOW}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
Â  Â  if [[ $DELETE_MODE -eq 1 && $DRY_RUN -eq 0 && $FORCE_SYSTEM_DELETE -eq 0 && $INTERACTIVE_DELETE -eq 0 ]]; then
Â  Â  Â  echo -ne "${YELLOW}Proceed with these settings? (y/N): ${NC}"
Â  Â  Â  read -r response
Â  Â  Â  [[ "$response" != "y" && "$response" != "Y" ]] && exit 0
Â  Â  fi
Â  fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STATE MANAGEMENT FUNCTIONS
# Functions for saving and loading the scan state to allow for interrupted
# scans to be resumed.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
save_state() {
Â  cat > "$HOME/.dupefinder_state" << EOF
SEARCH_PATH="$SEARCH_PATH"
OUTPUT_DIR="$OUTPUT_DIR"
HASH_ALGORITHM="$HASH_ALGORITHM"
TEMP_DIR="$TEMP_DIR"
SCAN_START_TIME="$SCAN_START_TIME"
EOF
Â  chmod 600 "$HOME/.dupefinder_state"
Â  [[ $VERBOSE -eq 1 ]] && echo -e "${CYAN}State saved to ~/.dupefinder_state${NC}"
}

load_state() {
Â  if [[ -f "$HOME/.dupefinder_state" ]]; then
Â  Â  local owner perm
Â  Â  owner=$(stat -c "%U" "$HOME/.dupefinder_state" 2>/dev/null)
Â  Â  perm=$(stat -c "%a" "$HOME/.dupefinder_state" 2>/dev/null)
Â  Â  if [[ "$owner" != "$USER" || "$perm" -gt 600 ]]; then
Â  Â  Â  echo -e "${RED}Unsafe resume file permissions/ownership; ignoring.${NC}"
Â  Â  Â  return 1
Â  Â  fi
Â  Â  # shellcheck disable=SC1090
Â  Â  source "$HOME/.dupefinder_state"
Â  Â  echo -e "${CYAN}Resuming previous scan...${NC}"
Â  Â  return 0
Â  fi
Â  return 1
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION MANAGEMENT
# Handles the parsing of command-line arguments and loading of external
# configuration files.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
load_config() {
Â  if [[ -n "$CONFIG_FILE" && -f "$CONFIG_FILE" ]]; then
Â  Â  echo -e "${CYAN}Loading configuration from $CONFIG_FILE...${NC}"
Â  Â  # shellcheck disable=SC1090
Â  Â  source "$CONFIG_FILE"
Â  fi
}

parse_arguments() {
Â  while [[ $# -gt 0 ]]; do
Â  Â  case $1 in
Â  Â  Â  -p|--path) SEARCH_PATH="$2"; shift 2 ;;
Â  Â  Â  -o|--output) OUTPUT_DIR="$2"; shift 2 ;;
Â  Â  Â  -e|--exclude) EXCLUDE_PATHS+=("$2"); shift 2 ;;
Â  Â  Â  -m|--min-size) MIN_SIZE=$(parse_size "$2"); shift 2 ;;
Â  Â  Â  -M|--max-size) MAX_SIZE=$(parse_size "$2"); shift 2 ;;
Â  Â  Â  -h|--help) show_help; exit 0 ;;
Â  Â  Â  -V|--version) echo "DupeFinder Pro v$VERSION by $AUTHOR"; exit 0 ;;
Â  Â  Â  --skip-system)
Â  Â  Â  Â  SKIP_SYSTEM_FOLDERS=1
Â  Â  Â  Â  echo -e "${GREEN}System folders will be excluded from scanning${NC}"
Â  Â  Â  Â  shift ;;
Â  Â  Â  --force-system)
Â  Â  Â  Â  FORCE_SYSTEM_DELETE=1
Â  Â  Â  Â  echo -e "${RED}âš  WARNING: Force system delete mode enabled - BE VERY CAREFUL!${NC}"
Â  Â  Â  Â  shift ;;
Â  Â  Â  -f|--follow-symlinks) FOLLOW_SYMLINKS=1; shift ;;
Â  Â  Â  -z|--empty) EMPTY_FILES=1; MIN_SIZE=0; shift ;;
Â  Â  Â  -a|--all) HIDDEN_FILES=1; shift ;;
Â  Â  Â  -l|--level) MAX_DEPTH="$2"; shift 2 ;;
Â  Â  Â  -t|--pattern) FILE_PATTERN+=("$2"); shift 2 ;;
Â  Â  Â  --fast) FAST_MODE=1; shift ;;
Â  Â  Â  --fuzzy) FUZZY_MATCH=1; shift ;;
Â  Â  Â  --similarity) SIMILARITY_THRESHOLD="$2"; shift 2 ;;
Â  Â  Â  --verify) VERIFY_MODE=1; shift ;;
Â  Â  Â  -d|--delete) DELETE_MODE=1; shift ;;
Â  Â  Â  -i|--interactive) INTERACTIVE_DELETE=1; DELETE_MODE=1; shift ;;
Â  Â  Â  -n|--dry-run) DRY_RUN=1; shift ;;
Â  Â  Â  --trash) USE_TRASH=1; shift ;;
Â  Â  Â  --hardlink) HARDLINK_MODE=1; shift ;;
Â  Â  Â  --quarantine) QUARANTINE_DIR="$2"; shift 2 ;;
Â  Â  Â  -k|--keep-newest) KEEP_NEWEST=1; shift ;;
Â  Â  Â  -K|--keep-oldest) KEEP_OLDEST=1; shift ;;
Â  Â  Â  --keep-path) KEEP_PATH_PRIORITY="$2"; shift 2 ;;
Â  Â  Â  --smart-delete) SMART_DELETE=1; shift ;;
Â  Â  Â  --auto-select) AUTO_SELECT_LOCATION="$2"; shift 2 ;;
Â  Â  Â  --threads) THREADS="$2"; shift 2 ;;
Â  Â  Â  --cache) USE_CACHE=1; shift ;;
Â  Â  Â  --save-checksums) SAVE_CHECKSUMS=1; shift ;;
Â  Â  Â  --no-progress) PROGRESS_BAR=0; shift ;;
Â  Â  Â  --parallel) USE_PARALLEL=1; shift ;;
Â  Â  Â  -c|--csv) CSV_REPORT="$2"; shift 2 ;;
Â  Â  Â  --json) JSON_REPORT="$2"; shift 2 ;;
Â  Â  Â  --email) EMAIL_REPORT="$2"; shift 2 ;;
Â  Â  Â  --log) LOG_FILE="$2"; shift 2 ;;
Â  Â  Â  -v|--verbose) VERBOSE=1; shift ;;
Â  Â  Â  -q|--quiet) QUIET=1; PROGRESS_BAR=0; shift ;;
Â  Â  Â  -s|--sha256) HASH_ALGORITHM="sha256sum"; shift ;;
Â  Â  Â  --sha512) HASH_ALGORITHM="sha512sum"; shift ;;
Â  Â  Â  --backup) BACKUP_DIR="$2"; shift 2 ;;
Â  Â  Â  --config) CONFIG_FILE="$2"; shift 2 ;;
Â  Â  Â  --exclude-list) EXCLUDE_LIST_FILE="$2"; shift 2 ;;
Â  Â  Â  --db-path) DB_CACHE="$2"; CHECKSUM_DB="${2%.db}_checksums.db"; shift 2 ;;
Â  Â  Â  --resume) RESUME_STATE=1; shift ;;
Â  Â  Â  *) echo -e "${RED}Unknown option: $1${NC}"; show_help; exit 1 ;;
Â  Â  esac
Â  done
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INITIALIZATION AND VALIDATION
# Checks for dependencies, validates input parameters, and sets up the
# execution environment.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
init_logging() {
Â  if [[ -n "$LOG_FILE" ]]; then
Â  Â  echo "$(date): DupeFinder Pro v$VERSION started by $USER" >> "$LOG_FILE"
Â  Â  echo "$(date): Search path: $SEARCH_PATH" >> "$LOG_FILE"
Â  Â  echo "$(date): System protection: $([ $SKIP_SYSTEM_FOLDERS -eq 1 ] && echo "ENABLED" || echo "DISABLED")" >> "$LOG_FILE"
Â  fi
}

check_dependencies() {
Â  # Check for SQLite3 if caching is requested
Â  if [[ $USE_CACHE -eq 1 || $SAVE_CHECKSUMS -eq 1 ]]; then
Â  Â  if ! command -v sqlite3 &>/dev/null; then
Â  Â  Â  echo -e "${RED}Error: sqlite3 is not installed. Cache/checksum disabled.${NC}"
Â  Â  Â  echo -e "${YELLOW}Install with: sudo apt install sqlite3${NC}"
Â  Â  Â  USE_CACHE=0
Â  Â  Â  SAVE_CHECKSUMS=0
Â  Â  fi
Â  fi
Â  # Check for trash-cli if trash mode is requested
Â  if [[ $USE_TRASH -eq 1 ]] && ! command -v trash-put &>/dev/null; then
Â  Â  echo -e "${YELLOW}Warning: trash-cli not installed. Falling back to rm.${NC}"
Â  Â  echo -e "${YELLOW}Install with: sudo apt install trash-cli${NC}"
Â  Â  USE_TRASH=0
Â  fi
Â  # Check for GNU parallel if requested
Â  if [[ $USE_PARALLEL -eq 1 ]] && ! command -v parallel &>/dev/null; then
Â  Â  echo -e "${YELLOW}Warning: GNU parallel not installed. Using xargs.${NC}"
Â  Â  echo -e "${YELLOW}Install with: sudo apt install parallel${NC}"
Â  Â  USE_PARALLEL=0
Â  fi
Â  # Check for mail command if email reporting is requested
Â  if [[ -n "$EMAIL_REPORT" ]] && ! command -v mail &>/dev/null; then
Â  Â  echo -e "${YELLOW}Warning: 'mail' command not found. Email disabled.${NC}"
Â  Â  EMAIL_REPORT=""
Â  fi
Â  # Check for jq if JSON reporting is requested
Â  if [[ -n "$JSON_REPORT" ]] && ! command -v jq &>/dev/null; then
Â  Â  echo -e "${RED}Error: jq is not installed. JSON report disabled.${NC}"
Â  Â  echo -e "${YELLOW}Install with: sudo apt install jq${NC}"
Â  Â  JSON_REPORT=""
Â  fi
}

validate_inputs() {
Â  # Attempt to resume previous scan if requested
Â  if [[ $RESUME_STATE -eq 1 ]] && load_state; then
Â  Â  echo -e "${GREEN}Resuming previous scan${NC}"
Â  fi
Â  # Validate search path existence
Â  if [[ ! -d "$SEARCH_PATH" ]]; then
Â  Â  echo -e "${RED}Error: Search path does not exist: $SEARCH_PATH${NC}"
Â  Â  exit 1
Â  fi
Â  # Create and validate output directory
Â  mkdir -p "$OUTPUT_DIR" || {
Â  Â  echo -e "${RED}Cannot create output directory: $OUTPUT_DIR${NC}"
Â  Â  exit 1
Â  }
Â  if [[ ! -w "$OUTPUT_DIR" ]]; then
Â  Â  echo -e "${RED}Error: Cannot write to output directory: $OUTPUT_DIR${NC}"
Â  Â  exit 1
Â  fi
Â  # Validate thread count
Â  if ! [[ "$THREADS" =~ ^[0-9]+$ ]] || [[ "$THREADS" -lt 1 ]]; then
Â  Â  THREADS=$(nproc)
Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${YELLOW}Invalid thread count, using $THREADS threads${NC}"
Â  fi
Â  # Check for conflicting keep strategies
Â  if [[ $KEEP_NEWEST -eq 1 && $KEEP_OLDEST -eq 1 ]]; then
Â  Â  echo -e "${RED}Error: Cannot use both --keep-newest and --keep-oldest${NC}"
Â  Â  exit 1
Â  fi
Â  # Validate and create quarantine directory if specified
Â  if [[ -n "$QUARANTINE_DIR" ]]; then
Â  Â  mkdir -p "$QUARANTINE_DIR" || {
Â  Â  Â  echo -e "${RED}Cannot create quarantine directory${NC}"
Â  Â  Â  exit 1
Â  Â  }
Â  Â  [[ ! -w "$QUARANTINE_DIR" ]] && {
Â  Â  Â  echo -e "${RED}Quarantine directory not writable${NC}"
Â  Â  Â  exit 1
Â  Â  }
Â  fi
Â  # Validate and create backup directory if specified
Â  if [[ -n "$BACKUP_DIR" ]]; then
Â  Â  mkdir -p "$BACKUP_DIR" || {
Â  Â  Â  echo -e "${RED}Cannot create backup directory${NC}"
Â  Â  Â  exit 1
Â  Â  }
Â  Â  [[ ! -w "$BACKUP_DIR" ]] && {
Â  Â  Â  echo -e "${RED}Backup directory not writable${NC}"
Â  Â  Â  exit 1
Â  Â  }
Â  fi
Â  # Process exclude list file if provided
Â  if [[ -n "$EXCLUDE_LIST_FILE" && -f "$EXCLUDE_LIST_FILE" ]]; then
Â  Â  while IFS= read -r line; do
Â  Â  Â  [[ -n "$line" && ! "$line" =~ ^# ]] && EXCLUDE_PATHS+=("$line")
Â  Â  done < "$EXCLUDE_LIST_FILE"
Â  fi
Â  # Add system folders to exclude list if requested
Â  if [[ $SKIP_SYSTEM_FOLDERS -eq 1 ]]; then
Â  Â  for sys_folder in "${SYSTEM_FOLDERS[@]}"; do
Â  Â  Â  if [[ -d "$sys_folder" ]]; then
Â  Â  Â  Â  local already_excluded=0
Â  Â  Â  Â  for ex in "${EXCLUDE_PATHS[@]}"; do
Â  Â  Â  Â  Â  [[ "$ex" == "$sys_folder" ]] && already_excluded=1 && break
Â  Â  Â  Â  done
Â  Â  Â  Â  [[ $already_excluded -eq 0 ]] && EXCLUDE_PATHS+=("$sys_folder")
Â  Â  Â  fi
Â  Â  done
Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${CYAN}Excluding system folders: ${SYSTEM_FOLDERS[*]}${NC}"
Â  fi
Â  # Safety warning for root execution without system protection
Â  if [[ "$USER" == "root" && $SKIP_SYSTEM_FOLDERS -eq 0 ]]; then
Â  Â  echo -e "${YELLOW}âš  WARNING: Running as root without --skip-system${NC}"
Â  Â  echo -e "${YELLOW}Â  System files could be affected. Consider using --skip-system${NC}"
Â  Â  if [[ $DELETE_MODE -eq 1 && $FORCE_SYSTEM_DELETE -eq 0 ]]; then
Â  Â  Â  echo -ne "${YELLOW}Â  Continue anyway? (y/N): ${NC}"
Â  Â  Â  read -r response
Â  Â  Â  [[ "$response" != "y" && "$response" != "Y" ]] && exit 1
Â  Â  fi
Â  fi
Â  # Display warning about excluded external media
Â  if printf '%s\n' "${EXCLUDE_PATHS[@]}" | grep -qE '^/mnt$|^/media$'; then
Â  Â  echo -e "${YELLOW}Note:${NC} /mnt and /media are excluded by default."
Â  Â  echo -e "${YELLOW}Â  Â  Â  Remove from --exclude to scan external drives.${NC}"
Â  fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATABASE CACHE MANAGEMENT
# SQLite-based caching for improved performance on repeated scans.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
init_cache() {
Â  if [[ $USE_CACHE -eq 1 || $SAVE_CHECKSUMS -eq 1 ]]; then
Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${CYAN}Initializing cache database...${NC}"
Â  Â  sqlite3 "$DB_CACHE" << 'EOF'
CREATE TABLE IF NOT EXISTS file_hashes (
Â  path TEXT PRIMARY KEY,
Â  hash TEXT NOT NULL,
Â  size INTEGER NOT NULL,
Â  mtime INTEGER NOT NULL,
Â  last_scan INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_hash ON file_hashes(hash);
CREATE INDEX IF NOT EXISTS idx_size ON file_hashes(size);
EOF
Â  Â  # Clean old entries (older than 30 days) to prevent the database from growing indefinitely
Â  Â  local cutoff=$(($(date +%s) - 2592000))
Â  Â  sqlite3 "$DB_CACHE" "DELETE FROM file_hashes WHERE last_scan < $cutoff;" >/dev/null 2>&1
Â  Â  # Initialize SQL buffer for batch operations
Â  Â  : > "$TEMP_DIR/sql_buffer.sql"
Â  fi
}

flush_cache_batch() {
Â  if [[ $USE_CACHE -eq 1 || $SAVE_CHECKSUMS -eq 1 ]]; then
Â  Â  if [[ -s "$TEMP_DIR/sql_buffer.sql" ]]; then
Â  Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${CYAN}Flushing batched SQLite writes...${NC}"
Â  Â  Â  # Wrap all operations in a single transaction for better performance
Â  Â  Â  printf 'BEGIN IMMEDIATE;\n' > "$TEMP_DIR/sql_txn.sql"
Â  Â  Â  cat "$TEMP_DIR/sql_buffer.sql" >> "$TEMP_DIR/sql_txn.sql"
Â  Â  Â  printf 'COMMIT;\n' >> "$TEMP_DIR/sql_txn.sql"
Â  Â  Â  sqlite3 "$DB_CACHE" < "$TEMP_DIR/sql_txn.sql" >/dev/null 2>&1
Â  Â  Â  # Clear buffer for next batch
Â  Â  Â  : > "$TEMP_DIR/sql_buffer.sql"
Â  Â  fi
Â  fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FILE DISCOVERY
# Finds all files matching the specified criteria using the 'find' command.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
find_files() {
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ” Scanning filesystem...${NC}"
Â  local find_cmd="find"
Â  local args=("$SEARCH_PATH")
Â  # Add max depth if specified
Â  [[ -n "$MAX_DEPTH" ]] && args+=(-maxdepth "$MAX_DEPTH")
Â  # Add exclude paths with proper pruning
Â  if [[ ${#EXCLUDE_PATHS[@]} -gt 0 ]]; then
Â  Â  args+=(\()
Â  Â  local first=1
Â  Â  for ex in "${EXCLUDE_PATHS[@]}"; do
Â  Â  Â  if [[ $first -eq 1 ]]; then
Â  Â  Â  Â  args+=(-path "$ex" -prune)
Â  Â  Â  Â  first=0
Â  Â  Â  else
Â  Â  Â  Â  args+=(-o -path "$ex" -prune)
Â  Â  Â  fi
Â  Â  done
Â  Â  args+=(\) -o)
Â  fi
Â  # Add file type and other filters
Â  args+=(-type f)
Â  [[ $HIDDEN_FILES -eq 0 ]] && args+=(-not -path '*/.*')
Â  [[ $FOLLOW_SYMLINKS -eq 0 ]] && args+=(-not -type l)
Â  [[ $MIN_SIZE -gt 0 ]] && args+=(-size "+${MIN_SIZE}c")
Â  [[ -n "$MAX_SIZE" ]] && args+=(-size "-${MAX_SIZE}c")
Â  # Add file pattern filters if specified
Â  if [[ ${#FILE_PATTERN[@]} -gt 0 ]]; then
Â  Â  args+=(\()
Â  Â  local firstp=1
Â  Â  for pat in "${FILE_PATTERN[@]}"; do
Â  Â  Â  if [[ $firstp -eq 1 ]]; then
Â  Â  Â  Â  args+=(-name "$pat")
Â  Â  Â  Â  firstp=0
Â  Â  Â  else
Â  Â  Â  Â  args+=(-o -name "$pat")
Â  Â  Â  fi
Â  Â  done
Â  Â  args+=(\))
Â  fi
Â  # Output null-delimited for safety with file paths
Â  args+=(-print0)
Â  [[ $VERBOSE -eq 1 ]] && echo -e "${CYAN}Find command:${NC} $find_cmd ${args[*]}"
Â  # Execute find and save results
Â  "$find_cmd" "${args[@]}" 2>/dev/null > "$TEMP_DIR/files.list"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HASH CALCULATION
# Calculates checksums for all discovered files, with parallelization and
# caching for performance.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
hash_worker() {
Â  local file="$1"
Â  local algo="$2"
Â  local fast="$3"
Â  local worker_id="$4"
Â  # Skip unreadable files silently
Â  [[ ! -r "$file" ]] && return 0
Â  local mtime size hash
Â  mtime=$(stat -c%Y "$file" 2>/dev/null) || mtime=0
Â  size=$(stat -c%s "$file" 2>/dev/null) || size=0
Â  if [[ "$fast" == "1" ]]; then
Â  Â  # Fast mode: use size and partial name hash
Â  Â  local name_hash
Â  Â  name_hash=$(basename "$file" | md5sum | cut -d' ' -f1)
Â  Â  hash="${size}_${name_hash:0:16}"
Â  else
Â  Â  # Full file hash
Â  Â  hash=$($algo "$file" 2>/dev/null | cut -d' ' -f1)
Â  fi
Â  [[ -z "$hash" ]] && return 0
Â  # Output result to worker-specific file
Â  printf '%s|%s|%s\n' "$hash" "$size" "$file"
Â  # Also prepare SQL for caching if enabled
Â  if [[ "$USE_CACHE" == "1" || "$SAVE_CHECKSUMS" == "1" ]]; then
Â  Â  local esc
Â  Â  esc=$(sql_escape "$file")
Â  Â  printf "INSERT OR REPLACE INTO file_hashes VALUES ('%s','%s',%s,%s,%s);\n" \
Â  Â  Â  "$esc" "$hash" "$size" "$mtime" "$(date +%s)" >> "$TEMP_DIR/sql_${worker_id}.sql"
Â  fi
}
# Export function and variables for parallel execution
export -f hash_worker sql_escape
export HASH_ALGORITHM FAST_MODE USE_CACHE DB_CACHE SAVE_CHECKSUMS TEMP_DIR
# Show progress during hash calculation
show_progress() {
Â  local current=$1
Â  local total=$2
Â  [[ $PROGRESS_BAR -eq 0 || $QUIET -eq 1 ]] && return
Â  local width=50
Â  (( total == 0 )) && return
Â  local pct=$(( current * 100 / total ))
Â  (( pct > 100 )) && pct=100
Â  local filled=$(( pct * width / 100 ))
Â  printf "\r${CYAN}Progress: [${NC}"
Â  printf "%${filled}s" | tr ' ' 'â–ˆ'
Â  printf "%$((width - filled))s" | tr ' ' 'â–‘'
Â  printf "${CYAN}] %3d%% (%d/%d)${NC}" $pct $current $total
}

calculate_hashes() {
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ“Š Calculating file hashes (threads: $THREADS)...${NC}"
Â  local total
Â  total=$(tr -cd '\0' < "$TEMP_DIR/files.list" | wc -c)
Â  TOTAL_FILES=$total
Â  : > "$TEMP_DIR/hashes.txt"
Â  : > "$TEMP_DIR/prog.count"
Â  if [[ $total -eq 0 ]]; then
Â  Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}No files matched criteria.${NC}"
Â  Â  return
Â  fi
Â  mkdir -p "$TEMP_DIR/workers"
Â  if [[ $USE_PARALLEL -eq 1 ]]; then
Â  Â  # Use GNU parallel for high-efficiency parallelization
Â  Â  < "$TEMP_DIR/files.list" parallel -0 -j "$THREADS" --no-notice --results "$TEMP_DIR/workers" \
Â  Â  Â  "worker_id=\$PARALLEL_SEQ; hash_worker {} '$HASH_ALGORITHM' '$FAST_MODE' \$worker_id; echo 1 >> '$TEMP_DIR/prog.count'" &
Â  else
Â  Â  # Use xargs as a fallback for parallelization
Â  Â  local job_num=0
Â  Â  while IFS= read -r -d '' filepath; do
Â  Â  Â  ((job_num++))
Â  Â  Â  local worker_id="worker_${job_num}"
Â  Â  Â  (
Â  Â  Â  Â  hash_worker "$filepath" "$HASH_ALGORITHM" "$FAST_MODE" "$worker_id" >> "$TEMP_DIR/workers/hash_${worker_id}.txt"
Â  Â  Â  Â  echo 1 >> "$TEMP_DIR/prog.count"
Â  Â  Â  ) &
Â  Â  Â  while [[ $(jobs -r | wc -l) -ge $THREADS ]]; do
Â  Â  Â  Â  sleep 0.05
Â  Â  Â  done
Â  Â  done < "$TEMP_DIR/files.list"
Â  Â  wait
Â  fi
Â  if [[ $USE_PARALLEL -eq 1 ]]; then
Â  Â  local pid=$!
Â  Â  while kill -0 $pid 2>/dev/null; do
Â  Â  Â  local processed
Â  Â  Â  processed=$(wc -l < "$TEMP_DIR/prog.count" 2>/dev/null || echo 0)
Â  Â  Â  show_progress "$processed" "$total"
Â  Â  Â  sleep 0.3
Â  Â  done
Â  Â  wait $pid
Â  fi
Â  show_progress "$total" "$total"
Â  [[ $PROGRESS_BAR -eq 1 && $QUIET -eq 0 ]] && echo ""
Â  [[ $VERBOSE -eq 1 ]] && echo -e "${CYAN}Aggregating hash results...${NC}"
Â  if [[ -d "$TEMP_DIR/workers" ]]; then
Â  Â  if [[ $USE_PARALLEL -eq 1 ]]; then
Â  Â  Â  find "$TEMP_DIR/workers" -name stdout -type f -exec cat {} \; >> "$TEMP_DIR/hashes.txt"
Â  Â  else
Â  Â  Â  cat "$TEMP_DIR/workers"/hash_*.txt >> "$TEMP_DIR/hashes.txt" 2>/dev/null
Â  Â  fi
Â  fi
Â  if [[ $USE_CACHE -eq 1 || $SAVE_CHECKSUMS -eq 1 ]]; then
Â  Â  : > "$TEMP_DIR/sql_buffer.sql"
Â  Â  if [[ $USE_PARALLEL -eq 1 ]]; then
Â  Â  Â  find "$TEMP_DIR/workers" -name "sql_*.sql" -type f -exec cat {} \; >> "$TEMP_DIR/sql_buffer.sql" 2>/dev/null
Â  Â  else
Â  Â  Â  cat "$TEMP_DIR"/sql_*.sql >> "$TEMP_DIR/sql_buffer.sql" 2>/dev/null
Â  Â  fi
Â  Â  flush_cache_batch
Â  fi
Â  rm -rf "$TEMP_DIR/workers" "$TEMP_DIR"/sql_*.sql 2>/dev/null
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DUPLICATE DETECTION
# Analyzes the calculated hashes to find and group duplicate files.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
find_duplicates() {
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ” Analyzing duplicates...${NC}"
Â  sort -t'|' -k1,1 "$TEMP_DIR/hashes.txt" > "$TEMP_DIR/sorted_hashes.txt"
Â  awk -F'|' '
Â  {
Â  Â  hash=$1; size=$2; file=$3
Â  Â  if (hash == prev_hash) {
Â  Â  Â  if (!(hash in groups)) {
Â  Â  Â  Â  groups[hash] = prev_file "|" prev_size
Â  Â  Â  Â  gcount++
Â  Â  Â  }
Â  Â  Â  groups[hash] = groups[hash] "\n" file "|" size
Â  Â  Â  dupcount++
Â  Â  Â  wasted += size
Â  Â  }
Â  Â  prev_hash = hash
Â  Â  prev_file = file
Â  Â  prev_size = size
Â  }
Â  END {
Â  Â  for (h in groups) {
Â  Â  Â  print h ":" groups[h]
Â  Â  Â  print "---"
Â  Â  }
Â  Â  print "STATS:" dupcount "|" wasted "|" gcount
Â  }' "$TEMP_DIR/sorted_hashes.txt" > "$TEMP_DIR/duplicates.txt"
Â  local stats
Â  stats=$(grep "^STATS:" "$TEMP_DIR/duplicates.txt" | cut -d: -f2)
Â  if [[ -n "$stats" ]]; then
Â  Â  TOTAL_DUPLICATES=$(echo "$stats" | cut -d'|' -f1)
Â  Â  TOTAL_SPACE_WASTED=$(echo "$stats" | cut -d'|' -f2)
Â  Â  TOTAL_DUPLICATE_GROUPS=$(echo "$stats" | cut -d'|' -f3)
Â  fi
Â  DUPLICATE_GROUPS=$(grep -v "^STATS:" "$TEMP_DIR/duplicates.txt")
Â  [[ $FUZZY_MATCH -eq 1 ]] && find_similar_files
}

find_similar_files() {
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ” Finding similar files (fuzzy)...${NC}"
Â  awk -F'|' -v threshold="$SIMILARITY_THRESHOLD" '
Â  BEGIN { print "---SIMILAR FILES---" }
Â  {
Â  Â  size=$2; file=$3
Â  Â  for (s in sizes) {
Â  Â  Â  diff = (s > size) ? s - size : size - s
Â  Â  Â  if (s > 0) {
Â  Â  Â  Â  pct = 100 - (diff * 100 / s)
Â  Â  Â  Â  if (pct >= threshold) {
Â  Â  Â  Â  Â  print "SIMILAR:" file "|" sizes[s] "|" pct "%"
Â  Â  Â  Â  }
Â  Â  Â  }
Â  Â  }
Â  Â  sizes[size] = file
Â  }' "$TEMP_DIR/sorted_hashes.txt" >> "$TEMP_DIR/duplicates.txt"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SMART DELETION STRATEGIES
# Functions to intelligently select which file in a duplicate group to keep,
# based on user-defined or default heuristics.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
get_location_priority() {
Â  local path="$1"
Â  local priority=50 # Default priority
Â  for loc in "${!LOCATION_PRIORITY[@]}"; do
Â  Â  if [[ "$path" == *"$loc"* ]]; then
Â  Â  Â  priority=${LOCATION_PRIORITY[$loc]}
Â  Â  Â  break
Â  Â  fi
Â  done
Â  echo "$priority"
}

select_file_to_keep() {
Â  local files=("$@")
Â  local keep_index=0
Â  local best_priority=999
Â  for i in "${!files[@]}"; do
Â  Â  local path="${files[$i]}"
Â  Â  local priority
Â  Â  priority=$(get_location_priority "$path")
Â  Â  if (( priority < best_priority )); then
Â  Â  Â  best_priority=$priority
Â  Â  Â  keep_index=$i
Â  Â  fi
Â  done
Â  echo "$keep_index"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENHANCED VERBOSE OUTPUT
# Displays detailed information about each group of duplicates found.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
show_duplicate_details() {
Â  [[ $VERBOSE -eq 0 ]] && return
Â  [[ $QUIET -eq 1 ]] && return

Â  if [[ $TOTAL_DUPLICATE_GROUPS -eq 0 ]]; then
Â  Â  echo -e "${YELLOW}No duplicate groups found to display.${NC}"
Â  Â  return
Â  fi

Â  echo ""
Â  echo -e "${WHITE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  echo -e "${BOLD}Â  Â  Â  Â  Â  Â  Â  Â  DUPLICATE GROUPS FOUND${NC}"
Â  echo -e "${WHITE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â Â 
Â  local gid=0
Â  while IFS= read -r line; do
Â  Â  if [[ "$line" =~ ^([a-f0-9]+):(.+)$ ]]; then
Â  Â  Â  ((gid++))
Â  Â  Â  local hash="${BASH_REMATCH[1]}"
Â  Â  Â  local files="${BASH_REMATCH[2]}"
Â  Â  Â  local arr=()
Â  Â  Â  local total_size=0

Â  Â  Â  while IFS='|' read -r filepath size; do
Â  Â  Â  Â  [[ -n "$filepath" ]] && arr+=("$filepath|$size")
Â  Â  Â  Â  ((total_size+=size))
Â  Â  Â  done <<< "$files"
Â  Â  Â Â 
Â  Â  Â  (( ${#arr[@]} < 2 )) && continue

Â  Â  Â  echo -e "${BOLD}${CYAN}Group $gid:${NC} Hash ${hash:0:16}... (Total size: $(format_size "$total_size"))"
Â  Â  Â  echo -e "${DIM}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"

Â  Â  Â  local keep_idx=0
Â  Â  Â  if [[ $SMART_DELETE -eq 1 ]]; then
Â  Â  Â  Â  local only_paths=()
Â  Â  Â  Â  for f in "${arr[@]}"; do only_paths+=("$(echo "$f" | cut -d'|' -f1)"); done
Â  Â  Â  Â  keep_idx=$(select_file_to_keep "${only_paths[@]}")
Â  Â  Â  elif [[ -n "$KEEP_PATH_PRIORITY" ]]; then
Â  Â  Â  Â  for i in "${!arr[@]}"; do
Â  Â  Â  Â  Â  local p=$(echo "${arr[$i]}" | cut -d'|' -f1)
Â  Â  Â  Â  Â  if [[ "$p" == "$KEEP_PATH_PRIORITY"* ]]; then keep_idx=$i; break; fi
Â  Â  Â  Â  done
Â  Â  Â  elif [[ $KEEP_NEWEST -eq 1 ]]; then
Â  Â  Â  Â  IFS=$'\n' read -r -d '' -a sorted_arr < <(
Â  Â  Â  Â  Â  for f in "${arr[@]}"; do local p=$(echo "$f" | cut -d'|' -f1); local m=$(stat -c '%Y' -- "$p" 2>/dev/null || echo 0); echo "$m|$f"; done | sort -rn | cut -d'|' -f2- && printf '\0'
Â  Â  Â  Â  ); arr=("${sorted_arr[@]}"); keep_idx=0
Â  Â  Â  elif [[ $KEEP_OLDEST -eq 1 ]]; then
Â  Â  Â  Â  # FIX START: Corrected pipeline for the for-loop to read into a variable correctly
Â  Â  Â  Â  IFS=$'\n' read -r -d '' -a sorted_arr < <(
Â  Â  Â  Â  Â  for f in "${arr[@]}"; do
Â  Â  Â  Â  Â  Â  local p=$(echo "$f" | cut -d'|' -f1)
Â  Â  Â  Â  Â  Â  local m=$(stat -c '%Y' -- "$p" 2>/dev/null || echo 0)
Â  Â  Â  Â  Â  Â  echo "$m|$f"
Â  Â  Â  Â  Â  done | sort -n | cut -d'|' -f2- && printf '\0'
Â  Â  Â  Â  )
Â  Â  Â  Â  arr=("${sorted_arr[@]}")
Â  Â  Â  Â  keep_idx=0
Â  Â  Â  Â  # FIX END
Â  Â  Â  else
Â  Â  Â  Â  IFS=$'\n' read -r -d '' -a arr < <(printf '%s\n' "${arr[@]}" | sort && printf '\0')
Â  Â  Â  Â  keep_idx=0
Â  Â  Â  fi

Â  Â  Â  for i in "${!arr[@]}"; do
Â  Â  Â  Â  local path size
Â  Â  Â  Â  path=$(echo "${arr[$i]}" | cut -d'|' -f1)
Â  Â  Â  Â  size=$(echo "${arr[$i]}" | cut -d'|' -f2)
Â  Â  Â  Â  local status=""
Â  Â  Â  Â  [[ $i -eq $keep_idx ]] && status=" (keep)"
Â  Â  Â  Â  is_in_system_folder "$path" && status=" (system file)"
Â  Â  Â  Â  echo -e "Â  - $(format_size "$size")Â  ${DIM}${path}${NC}${GREEN}${status}${NC}"
Â  Â  Â  done
Â  Â  Â  echo ""
Â  Â  fi
Â  done <<< "$DUPLICATE_GROUPS"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENHANCED INTERACTIVE MODE FUNCTIONS
# Provides a step-by-step interactive interface for managing duplicate files.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
show_file_details() {
Â  local file="$1"
Â  local size="$2"
Â  local is_keep="$3"
Â Â 
Â  if [[ ! -f "$file" ]]; then
Â  Â  echo -e "${RED}Â  Â  âš  File not found: $file${NC}"
Â  Â  return
Â  fi
Â Â 
Â  local mtime=$(stat -c '%Y' "$file" 2>/dev/null || echo 0)
Â  local mtime_human=$(date -d "@$mtime" '+%Y-%m-%d %H:%M:%S' 2>/dev/null || echo "Unknown")
Â  local perms=$(stat -c '%A' "$file" 2>/dev/null || echo "Unknown")
Â  local owner=$(stat -c '%U:%G' "$file" 2>/dev/null || echo "Unknown")
Â  local path_short="$file"
Â Â 
Â  if [[ ${#file} -gt 80 ]]; then
Â  Â  path_short="...${file: -75}"
Â  fi
Â Â 
Â  local status_icons=""
Â  [[ "$is_keep" == "true" ]] && status_icons+="ğŸ”’ "
Â  is_critical_system_file "$file" && status_icons+="âš ï¸ "
Â  is_in_system_folder "$file" && status_icons+="ğŸ›¡ï¸ "
Â  [[ -x "$file" ]] && status_icons+="âš¡ "
Â Â 
Â  echo -e "Â  Â  ${BOLD}ğŸ“„ ${path_short}${NC}"
Â  echo -e "Â  Â  ${CYAN}Size:${NC}Â  Â  Â $(format_size "$size") ($size bytes)"
Â  echo -e "Â  Â  ${CYAN}Modified:${NC} $mtime_human"
Â  echo -e "Â  Â  ${CYAN}Owner:${NC}Â  Â  $owner"
Â  echo -e "Â  Â  ${CYAN}Perms:${NC}Â  Â  $perms"
Â  [[ -n "$status_icons" ]] && echo -e "Â  Â  ${CYAN}Status:${NC}Â  Â $status_icons"
Â  echo ""
}

show_file_comparison() {
Â  local keep_file="$1"
Â  local keep_size="$2"
Â  local dup_file="$3"
Â  local dup_size="$4"
Â Â 
Â  echo -e "${WHITE}â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®${NC}"
Â  echo -e "${WHITE}â”‚Â  Â  Â  Â  Â  Â  Â  Â  Â  Â FILE COMPARISONÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚${NC}"
Â  echo -e "${WHITE}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤${NC}"
Â  echo -e "${GREEN}Â  ğŸ”’ KEEP (Current choice):${NC}"
Â  show_file_details "$keep_file" "$keep_size" "true"
Â  echo -e "${WHITE}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤${NC}"
Â  echo -e "${YELLOW}Â  ğŸ”„ DUPLICATE:${NC}"
Â  show_file_details "$dup_file" "$dup_size" "false"
Â  echo -e "${WHITE}â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯${NC}"
}

show_interactive_menu() {
Â  local group_num="$1"
Â  local total_groups="$2"
Â  local dup_file="$3"
Â  local freed_space="$4"
Â Â 
Â  echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  echo -e "${BOLD}Â  Interactive Mode - Group $group_num of $total_groups${NC}"
Â  echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  echo ""
Â  echo -e "${BOLD}Available Actions:${NC}"
Â  echo ""
Â  echo -e "${GREEN}Â  [d] Delete${NC}Â  Â  Â - Remove the duplicate file permanently"
Â  echo -e "${BLUE}Â  [h] Hardlink${NC}Â  - Replace duplicate with hardlink (saves space)"
Â  echo -e "${YELLOW}Â  [s] Skip${NC}Â  Â  Â  Â - Keep both files, move to next"
Â  echo -e "${CYAN}Â  [k] Keep This${NC}Â  - Mark this file as the one to keep instead"
Â  echo -e "${MAGENTA}Â  [v] View${NC}Â  Â  Â  Â - Open file in default application"
Â  echo -e "${WHITE}Â  [i] Info${NC}Â  Â  Â  Â - Show detailed file information"
Â  echo -e "${DIM}Â  [a] Apply to All${NC}- Apply current choice to remaining files"
Â  echo -e "${RED}Â  [q] Quit${NC}Â  Â  Â  Â - Stop processing and exit"
Â  echo ""
Â  echo -e "${DIM}Potential space savings: $(format_size "$freed_space")${NC}"
Â  echo ""
}

get_interactive_choice() {
Â  local default="${1:-d}"
Â  echo -ne "${BOLD}Choose action [${default}]: ${NC}"
Â  read -r -n 1 response
Â  echo ""
Â  response=${response,,}
Â  [[ -z "$response" ]] && response="$default"
Â  echo "$response"
}

open_file_viewer() {
Â  local file="$1"
Â  if command -v xdg-open >/dev/null 2>&1; then
Â  Â  echo -e "${CYAN}Opening file in default application...${NC}"
Â  Â  xdg-open "$file" 2>/dev/null &
Â  elif command -v open >/dev/null 2>&1; then
Â  Â  echo -e "${CYAN}Opening file in default application...${NC}"
Â  Â  open "$file" 2>/dev/null &
Â  elif command -v start >/dev/null 2>&1; then
Â  Â  echo -e "${CYAN}Opening file in default application...${NC}"
Â  Â  start "$file" 2>/dev/null &
Â  else
Â  Â  echo -e "${YELLOW}No file viewer available. File path: $file${NC}"
Â  fi
Â  echo -ne "${DIM}Press Enter to continue...${NC}"
Â  read -r
}

show_group_progress() {
Â  local current="$1"
Â  local total="$2"
Â  local processed_size="$3"
Â  if [[ $total -gt 0 ]]; then
Â  Â  local pct=$((current * 100 / total))
Â  Â  echo -e "${DIM}Progress: Group $current/$total (${pct}%) | Space processed: $(format_size "$processed_size")${NC}"
Â  fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FILE OPERATIONS
# Core functions for performing file actions like backup, deletion, and
# hardlinking. This section also contains the main deletion logic.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
backup_file() {
Â  local file="$1"
Â  [[ -z "$BACKUP_DIR" ]] && return 0
Â  local timestamp dir relative_path target
Â  timestamp=$(date +%Y%m%d_%H%M%S)
Â  dir="$BACKUP_DIR/$timestamp"
Â  mkdir -p "$dir"
Â  relative_path="${file#/}"
Â  target="$dir/$relative_path"
Â  mkdir -p "$(dirname "$target")"
Â  if cp -p -- "$file" "$target" 2>/dev/null; then
Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${BLUE}Â  Backed up: $file${NC}"
Â  Â  return 0
Â  fi
Â  return 1
}

verify_identical() {
Â  local file1="$1"
Â  local file2="$2"
Â  [[ $VERIFY_MODE -eq 0 ]] && return 0
Â  if cmp -s -- "$file1" "$file2"; then
Â  Â  return 0
Â  fi
Â  echo -e "${YELLOW}Â  Warning: Same hash but content differs!${NC}"
Â  echo -e "${YELLOW}Â  A: $file1${NC}"
Â  echo -e "${YELLOW}Â  B: $file2${NC}"
Â  return 1
}

delete_duplicates() {
Â  if [[ $DELETE_MODE -eq 0 && $HARDLINK_MODE -eq 0 && -z "$QUARANTINE_DIR" ]]; then
Â  Â  return
Â  fi
Â  local action="Processing"
Â  [[ $DELETE_MODE -eq 1 ]] && action="Deleting"
Â  [[ $HARDLINK_MODE -eq 1 ]] && action="Hardlinking"
Â  [[ -n "$QUARANTINE_DIR" ]] && action="Quarantining"
Â  [[ $DRY_RUN -eq 1 ]] && action="Would $action"
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ—‘ï¸Â  $action duplicate files...${NC}"
Â  local deleted=0 freed=0 links=0 processed_space=0
Â  local auto_choice="" apply_to_all=0
Â  local group_count=0
Â  local total_groups
Â  total_groups=$(echo "$DUPLICATE_GROUPS" | grep -c "^[a-f0-9]\+:")
Â  while IFS= read -r line; do
Â  Â  if [[ "$line" =~ ^([a-f0-9]+):(.+)$ ]]; then
Â  Â  Â  ((group_count++))
Â  Â  Â  local hash="${BASH_REMATCH[1]}"
Â  Â  Â  local files="${BASH_REMATCH[2]}"
Â  Â  Â  local arr=()
Â  Â  Â  while IFS='|' read -r filepath size; do
Â  Â  Â  Â  [[ -n "$filepath" ]] && arr+=("$filepath|$size")
Â  Â  Â  done <<< "$files"
Â  Â  Â  (( ${#arr[@]} < 2 )) && continue
Â  Â  Â  local keep_idx=0
Â  Â  Â  if [[ $SMART_DELETE -eq 1 ]]; then
Â  Â  Â  Â  local only_paths=()
Â  Â  Â  Â  for f in "${arr[@]}"; do only_paths+=("$(echo "$f" | cut -d'|' -f1)"); done
Â  Â  Â  Â  keep_idx=$(select_file_to_keep "${only_paths[@]}")
Â  Â  Â  elif [[ -n "$KEEP_PATH_PRIORITY" ]]; then
Â  Â  Â  Â  for i in "${!arr[@]}"; do
Â  Â  Â  Â  Â  local p=$(echo "${arr[$i]}" | cut -d'|' -f1)
Â  Â  Â  Â  Â  if [[ "$p" == "$KEEP_PATH_PRIORITY"* ]]; then keep_idx=$i; break; fi
Â  Â  Â  Â  done
Â  Â  Â  elif [[ $KEEP_NEWEST -eq 1 || $KEEP_OLDEST -eq 1 ]]; then
Â  Â  Â  Â  IFS=$'\n' read -r -d '' -a arr < <(
Â  Â  Â  Â  Â  for f in "${arr[@]}"; doÂ 
Â  Â  Â  Â  Â  Â  local p m
Â  Â  Â  Â  Â  Â  p=$(echo "$f" | cut -d'|' -f1)
Â  Â  Â  Â  Â  Â  m=$(stat -c '%Y' -- "$p" 2>/dev/null || echo 0)
Â  Â  Â  Â  Â  Â  echo "$m|$f"
Â  Â  Â  Â  Â  done | { [[ $KEEP_NEWEST -eq 1 ]] && sort -rn || sort -n; } | cut -d'|' -f2- && printf '\0'
Â  Â  Â  Â  )
Â  Â  Â  Â  keep_idx=0
Â  Â  Â  else
Â  Â  Â  Â  IFS=$'\n' read -r -d '' -a arr < <(printf '%s\n' "${arr[@]}" | sort && printf '\0')
Â  Â  Â  Â  keep_idx=0
Â  Â  Â  fi
Â  Â  Â  local keep_file keep_size
Â  Â  Â  keep_file=$(echo "${arr[$keep_idx]}" | cut -d'|' -f1)
Â  Â  Â  keep_size=$(echo "${arr[$keep_idx]}" | cut -d'|' -f2)
Â  Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${GREEN}Â  âœ“ Keeping: $keep_file${NC}"
Â  Â  Â  for i in "${!arr[@]}"; do
Â  Â  Â  Â  [[ $i -eq $keep_idx ]] && continue
Â  Â  Â  Â  local path size
Â  Â  Â  Â  path=$(echo "${arr[$i]}" | cut -d'|' -f1)
Â  Â  Â  Â  size=$(echo "${arr[$i]}" | cut -d'|' -f2)
Â  Â  Â  Â  ((processed_space+=size))
Â  Â  Â  Â  if ! verify_safe_to_delete "$path"; then
Â  Â  Â  Â  Â  echo -e "${GREEN}Â  âœ“ Skipped (safety check): $path${NC}"
Â  Â  Â  Â  Â  [[ -n "$LOG_FILE" ]] && echo "$(date): Skipped (safety): $path" >> "$LOG_FILE"
Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  fi
Â  Â  Â  Â  if [[ $SKIP_SYSTEM_FOLDERS -eq 1 ]] && is_in_system_folder "$path"; then
Â  Â  Â  Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${YELLOW}Â  âš  Skipped (system folder): $path${NC}"
Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  fi
Â  Â  Â  Â  if [[ $VERIFY_MODE -eq 1 ]]; then
Â  Â  Â  Â  Â  if ! verify_identical "$keep_file" "$path"; then
Â  Â  Â  Â  Â  Â  echo -e "${RED}Â  Skipping non-identical files${NC}"
Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  fi
Â  Â  Â  Â  fi
Â  Â  Â  Â  if [[ $INTERACTIVE_DELETE -eq 1 && $apply_to_all -eq 0 ]]; then
Â  Â  Â  Â  Â  clear
Â  Â  Â  Â  Â  show_group_progress "$group_count" "$total_groups" "$processed_space"
Â  Â  Â  Â  Â  echo ""
Â  Â  Â  Â  Â  show_file_comparison "$keep_file" "$keep_size" "$path" "$size"
Â  Â  Â  Â  Â  local choice=""
Â  Â  Â  Â  Â  while true; do
Â  Â  Â  Â  Â  Â  show_interactive_menu "$group_count" "$total_groups" "$path" "$size"
Â  Â  Â  Â  Â  Â  choice=$(get_interactive_choice "${auto_choice:-d}")
Â  Â  Â  Â  Â  Â  case "$choice" in
Â  Â  Â  Â  Â  Â  Â  d|D) echo -e "${YELLOW}Marking for deletion...${NC}"; break;;
Â  Â  Â  Â  Â  Â  Â  h|H) echo -e "${BLUE}Will create hardlink...${NC}"; HARDLINK_MODE=1; DELETE_MODE=0; break;;
Â  Â  Â  Â  Â  Â  Â  s|S) echo -e "${GREEN}Skipping this file...${NC}"; break;;
Â  Â  Â  Â  Â  Â  Â  k|K)
Â  Â  Â  Â  Â  Â  Â  Â  echo -e "${CYAN}Swapping keep choice...${NC}"
Â  Â  Â  Â  Â  Â  Â  Â  local temp_file="$keep_file"
Â  Â  Â  Â  Â  Â  Â  Â  local temp_size="$keep_size"
Â  Â  Â  Â  Â  Â  Â  Â  keep_file="$path"
Â  Â  Â  Â  Â  Â  Â  Â  keep_size="$size"
Â  Â  Â  Â  Â  Â  Â  Â  path="$temp_file"
Â  Â  Â  Â  Â  Â  Â  Â  size="$temp_size"
Â  Â  Â  Â  Â  Â  Â  Â  echo -e "${GREEN}Now keeping: $keep_file${NC}"; sleep 1; continue;;
Â  Â  Â  Â  Â  Â  Â  v|V) open_file_viewer "$path"; continue;;
Â  Â  Â  Â  Â  Â  Â  i|I)
Â  Â  Â  Â  Â  Â  Â  Â  clear
Â  Â  Â  Â  Â  Â  Â  Â  echo -e "${CYAN}=== DETAILED FILE INFORMATION ===${NC}"
Â  Â  Â  Â  Â  Â  Â  Â  echo ""
Â  Â  Â  Â  Â  Â  Â  Â  echo -e "${GREEN}KEEP FILE:${NC}"
Â  Â  Â  Â  Â  Â  Â  Â  show_file_details "$keep_file" "$keep_size" "true"
Â  Â  Â  Â  Â  Â  Â  Â  echo -e "${YELLOW}DUPLICATE FILE:${NC}"
Â  Â  Â  Â  Â  Â  Â  Â  show_file_details "$path" "$size" "false"
Â  Â  Â  Â  Â  Â  Â  Â  echo -ne "${DIM}Press Enter to continue...${NC}"; read -r; continue;;
Â  Â  Â  Â  Â  Â  Â  a|A)
Â  Â  Â  Â  Â  Â  Â  Â  echo -ne "${YELLOW}Apply this choice (${choice}) to all remaining duplicates? (y/N): ${NC}"; read -r confirm
Â  Â  Â  Â  Â  Â  Â  Â  if [[ "$confirm" =~ ^[Yy] ]]; then apply_to_all=1; auto_choice="$choice"; echo -e "${GREEN}Will apply '$choice' to remaining files...${NC}"; sleep 1; fi
Â  Â  Â  Â  Â  Â  Â  Â  break;;
Â  Â  Â  Â  Â  Â  Â  q|Q) echo -e "${YELLOW}Quitting interactive mode...${NC}"; break 3;;
Â  Â  Â  Â  Â  Â  Â  *) echo -e "${RED}Invalid choice. Please try again.${NC}"; sleep 1; continue;;
Â  Â  Â  Â  Â  Â  esac
Â  Â  Â  Â  Â  done
Â  Â  Â  Â  Â  if [[ "$choice" =~ ^[Ss]$ ]]; then echo -e "${GREEN}Â  âœ“ Skipped: $path${NC}"; continue; fi
Â  Â  Â  Â  elif [[ $INTERACTIVE_DELETE -eq 1 && $apply_to_all -eq 1 ]]; then
Â  Â  Â  Â  Â  # Apply auto choice for non-interactive files in the loop
Â  Â  Â  Â  Â  local choice_auto="$auto_choice"
Â  Â  Â  Â  Â  if [[ "$choice_auto" =~ ^[Ss]$ ]]; then echo -e "${GREEN}Â  âœ“ Skipped (auto): $path${NC}"; continue; fi
Â  Â  Â  Â  Â  if [[ "$choice_auto" =~ ^[Kk]$ ]]; then
Â  Â  Â  Â  Â  Â  local temp_file="$keep_file"
Â  Â  Â  Â  Â  Â  local temp_size="$keep_size"
Â  Â  Â  Â  Â  Â  keep_file="$path"
Â  Â  Â  Â  Â  Â  keep_size="$size"
Â  Â  Â  Â  Â  Â  path="$temp_file"
Â  Â  Â  Â  Â  Â  size="$temp_size"
Â  Â  Â  Â  Â  Â  [[ $VERBOSE -eq 1 ]] && echo -e "${CYAN}Â  Swapping keep to: $keep_file (auto)${NC}"
Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  fi
Â  Â  Â  Â  fi
Â  Â  Â  Â  if [[ -n "$BACKUP_DIR" && $DRY_RUN -eq 0 ]]; then backup_file "$path"; fi
Â  Â  Â  Â  if [[ $DRY_RUN -eq 1 ]]; then
Â  Â  Â  Â  Â  if [[ $HARDLINK_MODE -eq 1 ]]; then echo -e "${YELLOW}Â  Would hardlink: $path -> $keep_file${NC}";
Â  Â  Â  Â  Â  elif [[ -n "$QUARANTINE_DIR" ]]; then echo -e "${YELLOW}Â  Would quarantine: $path${NC}";
Â  Â  Â  Â  Â  else echo -e "${YELLOW}Â  Would delete: $path${NC}"; fi
Â  Â  Â  Â  Â  ((deleted++)); ((freed+=size))
Â  Â  Â  Â  elif [[ $HARDLINK_MODE -eq 1 ]]; then
Â  Â  Â  Â  Â  if ln -f -- "$keep_file" "$path" 2>/dev/null; then ((links++)); ((freed+=size)); [[ $VERBOSE -eq 1 ]] && echo -e "${BLUE}Â  â†” Hardlinked: $path${NC}"; [[ -n "$LOG_FILE" ]] && echo "$(date): Hardlinked: $path -> $keep_file" >> "$LOG_FILE"; else echo -e "${RED}Â  Failed to hardlink: $path${NC}"; fi
Â  Â  Â  Â  elif [[ -n "$QUARANTINE_DIR" ]]; then
Â  Â  Â  Â  Â  local qfile="$QUARANTINE_DIR/$(basename "$path")_$(date +%s)"
Â  Â  Â  Â  Â  if mv -- "$path" "$qfile" 2>/dev/null; then ((deleted++)); ((freed+=size)); [[ $VERBOSE -eq 1 ]] && echo -e "${YELLOW}Â  âš  Quarantined: $path${NC}"; [[ -n "$LOG_FILE" ]] && echo "$(date): Quarantined: $path -> $qfile" >> "$LOG_FILE"; fi
Â  Â  Â  Â  elif [[ $USE_TRASH -eq 1 ]]; then
Â  Â  Â  Â  Â  if trash-put -- "$path" 2>/dev/null; then ((deleted++)); ((freed+=size)); [[ $VERBOSE -eq 1 ]] && echo -e "${YELLOW}Â  ğŸ—‘ Trashed: $path${NC}"; [[ -n "$LOG_FILE" ]] && echo "$(date): Trashed: $path" >> "$LOG_FILE"; fi
Â  Â  Â  Â  else
Â  Â  Â  Â  Â  if rm -f -- "$path" 2>/dev/null; then ((deleted++)); ((freed+=size)); [[ $VERBOSE -eq 1 ]] && echo -e "${RED}Â  âœ— Deleted: $path${NC}"; [[ -n "$LOG_FILE" ]] && echo "$(date): Deleted: $path" >> "$LOG_FILE"; fi
Â  Â  Â  Â  fi
Â  Â  Â  done
Â  Â  fi
Â  done <<< "$DUPLICATE_GROUPS"
Â  FILES_DELETED=$deleted
Â  SPACE_FREED=$freed
Â  if [[ $QUIET -eq 0 ]]; then
Â  Â  if [[ $HARDLINK_MODE -eq 1 ]]; then echo -e "${GREEN}âœ… Created $links hardlinks, freed $(format_size $freed)${NC}";
Â  Â  else echo -e "${GREEN}âœ… Processed $deleted files, freed $(format_size $freed)${NC}"; fi
Â  fi
Â  if [[ $INTERACTIVE_DELETE -eq 1 ]]; then
Â  Â  clear
Â  Â  echo -e "${GREEN}ğŸ‰ Interactive processing completed!${NC}"
Â  Â  echo -e "${CYAN}Files processed: $deleted${NC}"
Â  Â  echo -e "${CYAN}Space freed: $(format_size $freed)${NC}"
Â  Â  echo ""
Â  fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REPORT GENERATION
# Functions for creating detailed reports in HTML, CSV, and JSON formats.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
generate_html_report() {
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ“„ Generating HTML report...${NC}"
Â  local report_file="$OUTPUT_DIR/$HTML_REPORT"
Â  {
Â  Â  cat << EOF
<!DOCTYPE html><html lang="en"><head>
<meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>DupeFinder Pro Report</title>
<style>
body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Arial,sans-serif;background:#f1f3f5;margin:0}
.container{max-width:1200px;margin:40px auto;background:#fff;border-radius:12px;box-shadow:0 20px 60px rgba(0,0,0,0.1);overflow:hidden}
header{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;padding:24px 28px}
h1{margin:0;font-size:28px}
.subtitle{opacity:.9;margin-top:6px}
.safety-badge{background:#4caf50;color:#fff;padding:4px 8px;border-radius:4px;font-size:12px;margin-left:10px}
.safety-warning{background:#ff9800}
.stats{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:16px;padding:20px;background:#f8f9fa}
.card{background:#fff;border:1px solid #eceff1;border-radius:8px;padding:16px;text-align:center}
.val{font-size:22px;color:#667eea;font-weight:700}
.label{color:#6c757d;text-transform:uppercase;font-size:12px;margin-top:4px}
.group{border-top:1px solid #f1f3f5}
.group .hdr{background:#fafbfc;padding:12px 16px;cursor:pointer;font-weight:600}
.group .files{padding:6px 16px 16px 16px;display:none}
.file{padding:8px 0;border-bottom:1px solid #f6f7f8}
.file:last-child{border-bottom:0}
.code{font-family:ui-monospace,Menlo,Consolas,monospace;font-size:12px;color:#495057}
.show .files{display:block}
.footer{padding:16px 20px;background:#fff;border-top:1px solid #eceff1}
.system-file{color:#d32f2f}
</style>
<script>
function toggle(id){var el=document.getElementById(id); if(el){el.classList.toggle('show');}}
</script>
</head><body>
<div class="container">
<header>
Â  <h1>DupeFinder Pro Report
Â  Â  $([ $SKIP_SYSTEM_FOLDERS -eq 1 ] && echo '<span class="safety-badge">System Protected</span>' || echo '<span class="safety-badge safety-warning">Full Scan</span>')
Â  </h1>
Â  <div class="subtitle">by ${AUTHOR} | Generated: $(date '+%B %d, %Y %H:%M:%S')</div>
</header>
<div class="stats">
Â  <div class="card"><div class="val">${TOTAL_FILES}</div><div class="label">Files Scanned</div></div>
Â  <div class="card"><div class="val">${TOTAL_DUPLICATES}</div><div class="label">Duplicates Found</div></div>
Â  <div class="card"><div class="val">${TOTAL_DUPLICATE_GROUPS}</div><div class="label">Duplicate Groups</div></div>
Â  <div class="card"><div class="val">$(format_size "${TOTAL_SPACE_WASTED:-0}")</div><div class="label">Space Wasted</div></div>
</div>
<div>
EOF
Â  Â  local gid=0
Â  Â  while IFS= read -r line; do
Â  Â  Â  if [[ "$line" =~ ^([a-f0-9]+):(.+)$ ]]; then
Â  Â  Â  Â  ((gid++))
Â  Â  Â  Â  local hash="${BASH_REMATCH[1]}"
Â  Â  Â  Â  local files="${BASH_REMATCH[2]}"
Â  Â  Â  Â  echo "<div id=\"g$gid\" class=\"group\">"
Â  Â  Â  Â  echo "<div class=\"hdr\" onclick=\"toggle('g$gid')\">Group $gid (Hash: ${hash:0:16}â€¦)</div>"
Â  Â  Â  Â  echo "<div class=\"files\">"
Â  Â  Â  Â  while IFS='|' read -r filepath size; do
Â  Â  Â  Â  Â  [[ -z "$filepath" ]] && continue
Â  Â  Â  Â  Â  local class=""
Â  Â  Â  Â  Â  is_in_system_folder "$filepath" && class="system-file"
Â  Â  Â  Â  Â  printf '<div class="file"><div class="code %s">%s</div><div>Size: %s</div></div>\n' \
Â  Â  Â  Â  Â  Â  "$class" \
Â  Â  Â  Â  Â  Â  "$(printf '%s' "$filepath" | sed 's/&/\&amp;/g;s/</\&lt;/g')" \
Â  Â  Â  Â  Â  Â  "$(format_size "$size")"
Â  Â  Â  Â  done <<< "$files"
Â  Â  Â  Â  echo "</div></div>"
Â  Â  Â  fi
Â  Â  done <<< "$DUPLICATE_GROUPS"
Â  Â  cat << EOF
</div>
<div class="footer">
Â  <small>Report generated with system protection: $([ $SKIP_SYSTEM_FOLDERS -eq 1 ] && echo "enabled" || echo "disabled")</small>
</div>
</div></body></html>
EOF
Â  } > "$report_file"
Â  [[ $QUIET -eq 0 ]] && echo -e "${GREEN}âœ… HTML report saved to: $report_file${NC}"
}

generate_csv_report() {
Â  [[ -z "$CSV_REPORT" ]] && return
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ“Š Generating CSV report...${NC}"
Â  local csv="$OUTPUT_DIR/$CSV_REPORT"
Â  echo "Hash,File Path,Size (bytes),Size (human),Group ID,System File" > "$csv"
Â  local gid=0
Â  while IFS= read -r line; do
Â  Â  if [[ "$line" =~ ^([a-f0-9]+):(.+)$ ]]; then
Â  Â  Â  ((gid++))
Â  Â  Â  local hash="${BASH_REMATCH[1]}"
Â  Â  Â  local files="${BASH_REMATCH[2]}"
Â  Â  Â  while IFS='|' read -r fp sz; do
Â  Â  Â  Â  [[ -z "$fp" ]] && continue
Â  Â  Â  Â  local is_system="No"
Â  Â  Â  Â  is_in_system_folder "$fp" && is_system="Yes"
Â  Â  Â  Â  printf '%s,"%s",%s,"%s",%s,%s\n' "$hash" "$fp" "$sz" "$(format_size "$sz")" "$gid" "$is_system" >> "$csv"
Â  Â  Â  done <<< "$files"
Â  Â  fi
Â  done <<< "$DUPLICATE_GROUPS"
Â  [[ $QUIET -eq 0 ]] && echo -e "${GREEN}âœ… CSV report saved to: $csv${NC}"
}

generate_json_report() {
Â  [[ -z "$JSON_REPORT" ]] && return
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ“‹ Generating JSON report...${NC}"
Â  local json="$OUTPUT_DIR/$JSON_REPORT"
Â  {
Â  Â  echo '{'
Â  Â  echo 'Â  "metadata": {'
Â  Â  printf 'Â  Â  "version": "%s", "author": "%s", "generated": "%s", ' "$VERSION" "$AUTHOR" "$(date -Iseconds)"
Â  Â  printf '"search_path": "%s", "system_protection": %s, ' "$SEARCH_PATH" "$([ $SKIP_SYSTEM_FOLDERS -eq 1 ] && echo "true" || echo "false")"
Â  Â  printf '"total_files": %s, "total_duplicates": %s, ' "${TOTAL_FILES:-0}" "${TOTAL_DUPLICATES:-0}"
Â  Â  printf '"total_groups": %s, "space_wasted": %s, ' "${TOTAL_DUPLICATE_GROUPS:-0}" "${TOTAL_SPACE_WASTED:-0}"
Â  Â  printf '"hash_algorithm": "%s"\n' "${HASH_ALGORITHM%%sum}"
Â  Â  echo 'Â  },'
Â  Â  echo 'Â  "groups": ['
Â  Â  local first_group=1
Â  Â  local gid=0
Â  Â  while IFS= read -r line; do
Â  Â  Â  if [[ "$line" =~ ^([a-f0-9]+):(.+)$ ]]; then
Â  Â  Â  Â  ((gid++))
Â  Â  Â  Â  local hash="${BASH_REMATCH[1]}"
Â  Â  Â  Â  local files="${BASH_REMATCH[2]}"
Â  Â  Â  Â  [[ $first_group -eq 0 ]] && echo ','
Â  Â  Â  Â  echo 'Â  Â  {'
Â  Â  Â  Â  printf 'Â  Â  Â  "id": %s, "hash": "%s", "files": [' "$gid" "$hash"
Â  Â  Â  Â  local first_file=1
Â  Â  Â  Â  while IFS='|' read -r fp sz; do
Â  Â  Â  Â  Â  [[ -z "$fp" ]] && continue
Â  Â  Â  Â  Â  [[ $first_file -eq 0 ]] && echo -n ','
Â  Â  Â  Â  Â  local is_system="false"
Â  Â  Â  Â  Â  is_in_system_folder "$fp" && is_system="true"
Â  Â  Â  Â  Â  printf '\nÂ  Â  Â  Â  {"path": %s, "size": %s, "system": %s}' "$(printf '%s' "$fp" | jq -Rsa . | sed 's/^"//;s/"$//')" "$sz" "$is_system"
Â  Â  Â  Â  Â  first_file=0
Â  Â  Â  Â  done <<< "$files"
Â  Â  Â  Â  echo -e '\nÂ  Â  Â  ]'
Â  Â  Â  Â  echo -n 'Â  Â  }'
Â  Â  Â  Â  first_group=0
Â  Â  Â  fi
Â  Â  done <<< "$DUPLICATE_GROUPS"
Â  Â  echo -e '\nÂ  ]'
Â  Â  echo '}'
Â  } | jq . > "$json" 2>/dev/null
Â  [[ $QUIET -eq 0 ]] && echo -e "${GREEN}âœ… JSON report saved to: $json${NC}"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EMAIL AND SUMMARY
# Functions for sending email notifications and displaying the final scan
# summary.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
calculate_duration() {
Â  local duration=$((SCAN_END_TIME - SCAN_START_TIME))
Â  local hours=$((duration/3600))
Â  local minutes=$(((duration%3600)/60))
Â  local seconds=$((duration%60))
Â  if (( hours > 0 )); then printf "%dh %dm %ds" "$hours" "$minutes" "$seconds";
Â  elif (( minutes > 0 )); then printf "%dm %ds" "$minutes" "$seconds";
Â  else printf "%ds" "$seconds"; fi
}

send_email_report() {
Â  [[ -z "$EMAIL_REPORT" ]] && return
Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}ğŸ“§ Sending email report...${NC}"
Â  local subject="DupeFinder Pro Report - $(date '+%Y-%m-%d')"
Â  local body="DupeFinder Pro Scan Results
Configuration:
Â  Search Path: $SEARCH_PATH
Â  System Protection: $([ $SKIP_SYSTEM_FOLDERS -eq 1 ] && echo "Enabled" || echo "Disabled")
Â  Hash Algorithm: ${HASH_ALGORITHM%%sum}
Results:
Â  Total Files Scanned: $TOTAL_FILES
Â  Duplicate Files Found: $TOTAL_DUPLICATES
Â  Duplicate Groups: $TOTAL_DUPLICATE_GROUPS
Â  Space Wasted: $(format_size ${TOTAL_SPACE_WASTED:-0})
Actions:
Â  Files Processed: $FILES_DELETED
Â  Space Freed: $(format_size ${SPACE_FREED:-0})
Performance:
Â  Scan Duration: $(calculate_duration)
Â  Threads Used: $THREADS
Reports:
Â  HTML Report: $OUTPUT_DIR/$HTML_REPORT"
Â  if command -v mail &>/dev/null; then
Â  Â  echo "$body" | mail -s "$subject" "$EMAIL_REPORT"
Â  Â  [[ $QUIET -eq 0 ]] && echo -e "${GREEN}âœ… Email sent to: $EMAIL_REPORT${NC}"
Â  else
Â  Â  [[ $QUIET -eq 0 ]] && echo -e "${YELLOW}âš  Mail command not available${NC}"
Â  fi
}

show_summary() {
Â  [[ $QUIET -eq 1 ]] && return
Â  echo ""
Â  echo -e "${WHITE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  echo -e "${BOLD}Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  SCAN SUMMARY${NC}"
Â  echo -e "${WHITE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
Â  echo -e "${CYAN}ğŸ“ Search Path:${NC}Â  Â  Â  Â  Â  $SEARCH_PATH"
Â  echo -e "${CYAN}ğŸ›¡ï¸Â  System Protection:${NC}Â  Â  $([ $SKIP_SYSTEM_FOLDERS -eq 1 ] && echo "ENABLED" || echo "DISABLED")"
Â  echo -e "${CYAN}ğŸ“Š Files Scanned:${NC}Â  Â  Â  Â  $TOTAL_FILES"
Â  echo -e "${CYAN}ğŸ”„ Duplicates Found:${NC}Â  Â  Â $TOTAL_DUPLICATES"
Â  echo -e "${CYAN}ğŸ“‚ Duplicate Groups:${NC}Â  Â  Â $TOTAL_DUPLICATE_GROUPS"
Â  echo -e "${CYAN}ğŸ’¾ Space Wasted:${NC}Â  Â  Â  Â  Â $(format_size ${TOTAL_SPACE_WASTED:-0})"
Â  if [[ $FILES_DELETED -gt 0 || $HARDLINK_MODE -eq 1 ]]; then
Â  Â  echo -e "${CYAN}âœ… Files Processed:${NC}Â  Â  Â  $FILES_DELETED"
Â  Â  echo -e "${CYAN}ğŸ’š Space Freed:${NC}Â  Â  Â  Â  Â  $(format_size ${SPACE_FREED:-0})"
Â  fi
Â  echo -e "${CYAN}â±ï¸Â  Scan Duration:${NC}Â  Â  Â  Â  $(calculate_duration)"
Â  echo -e "${CYAN}ğŸ”§ Hash Algorithm:${NC}Â  Â  Â  Â ${HASH_ALGORITHM%%sum}"
Â  echo -e "${CYAN}âš¡ Threads Used:${NC}Â  Â  Â  Â  Â $THREADS"
Â  echo -e "${WHITE}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
Â  echo -e "${CYAN}ğŸ“„ HTML Report:${NC}Â  Â  Â  Â  Â  $OUTPUT_DIR/$HTML_REPORT"
Â  [[ -n "$CSV_REPORT" ]] && \
Â  Â  echo -e "${CYAN}ğŸ“Š CSV Report:${NC}Â  Â  Â  Â  Â  Â $OUTPUT_DIR/$CSV_REPORT"
Â  [[ -n "$JSON_REPORT" ]] && \
Â  Â  echo -e "${CYAN}ğŸ“‹ JSON Report:${NC}Â  Â  Â  Â  Â  $OUTPUT_DIR/$JSON_REPORT"
Â  [[ -n "$LOG_FILE" ]] && \
Â  Â  echo -e "${CYAN}ğŸ“ Log File:${NC}Â  Â  Â  Â  Â  Â  Â $LOG_FILE"
Â  echo -e "${WHITE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN EXECUTION
# The main function orchestrates all operations in the correct sequence.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
main() {
Â  # Initialization and validation
Â  load_config
Â  check_dependencies
Â  SCAN_START_TIME=$(date +%s)
Â  init_logging
Â  [[ $QUIET -eq 0 ]] && show_header
Â  validate_inputs
Â  # Core operations
Â  init_cache
Â  find_files
Â  calculate_hashes
Â  find_duplicates
Â  show_duplicate_details
Â  show_safety_summary
Â  delete_duplicates
Â  # Finalize
Â  SCAN_END_TIME=$(date +%s)
Â  send_email_report
Â  show_summary
Â  # Display final message
Â  [[ $QUIET -eq 0 ]] && echo -e "\n${GREEN}âœ¨ Scan completed successfully!${NC}"
Â  [[ $QUIET -eq 0 ]] && echo -e "${DIM}DupeFinder Pro v$VERSION by $AUTHOR${NC}\n"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENTRY POINT
# Parses command-line arguments and begins the main execution loop.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
parse_arguments "$@"
main
exit 0
